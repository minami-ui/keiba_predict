{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5504ddc7",
   "metadata": {},
   "source": [
    "# はじめに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30b673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dff9f2",
   "metadata": {},
   "source": [
    "# 第1回：Pythonで競馬データをスクレイピングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a86771f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4312c176345f41a8b300c2dde68a4d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-37ec2000c808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#スクレイピングしてデータを保存\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mtest3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_race_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrace_id_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest3\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#.keys()は無くても大丈夫です\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mtest3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-37ec2000c808>\u001b[0m in \u001b[0;36mscrape_race_results\u001b[1;34m(race_id_list, pre_race_results)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://db.netkeiba.com/race/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrace_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mrace_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrace_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#競馬データスクレイピング\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "#現在ではインポートの仕方が下のように変わっています\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def scrape_race_results(race_id_list, pre_race_results={}):\n",
    "    #race_results = pre_race_results\n",
    "    race_results = pre_race_results.copy() #正しくはこちら。注意点で解説。\n",
    "    for race_id in tqdm(race_id_list):\n",
    "        if race_id in race_results.keys():\n",
    "            continue\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "            race_results[race_id] = pd.read_html(url)[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "#この部分は動画中に無いですが、捕捉できるエラーは拾った方が、エラーが出たときに分かりやすいです\n",
    "            #except Exception as e:\n",
    "            #print(e)\n",
    "        #break\n",
    "        #except:\n",
    "        #break\n",
    "    return race_results\n",
    "\n",
    "#レースIDのリストを作る\n",
    "race_id_list = []\n",
    "for place in range(1, 11, 1):\n",
    "    for kai in range(1, 6, 1):\n",
    "        for day in range(1, 13, 1):\n",
    "            for r in range(1, 13, 1):\n",
    "                race_id = \"2019\" + str(place).zfill(2) + str(kai).zfill(2) +\\\n",
    "        str(day).zfill(2) + str(r).zfill(2)\n",
    "                race_id_list.append(race_id)\n",
    "\n",
    "#スクレイピングしてデータを保存\n",
    "test3 = scrape_race_results(race_id_list)\n",
    "for key in test3: #.keys()は無くても大丈夫です\n",
    "    test3[key].index = [key] * len(test3[key])\n",
    "results = pd.concat([test3[key] for key in test3], sort=False) \n",
    "results.to_pickle('results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10694ad5",
   "metadata": {},
   "source": [
    "# 第2回・第3回 Pythonで競馬データを加工する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa669607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ整形\n",
    "def preprocessing(results):\n",
    "    df = results.copy()\n",
    "\n",
    "    # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "    df = df[~(df[\"着順\"].astype(str).str.contains(\"\\D\"))]\n",
    "    df[\"着順\"] = df[\"着順\"].astype(int)\n",
    "\n",
    "    # 性齢を性と年齢に分ける\n",
    "    df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "    df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "    # 馬体重を体重と体重変化に分ける\n",
    "    df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "    df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "\n",
    "    # データをint, floatに変換\n",
    "    df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "\n",
    "    # 不要な列を削除\n",
    "    df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\"], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5e78b",
   "metadata": {},
   "source": [
    "# 第4回 ロジスティック回帰で競馬予想してみた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4着以下を全て4にする\n",
    "clip_rank = lambda x: x if x < 4 else 4\n",
    "#動画中のresultsは、preprocessing関数で前処理が行われた後のデータ\n",
    "results[\"rank\"] = results[\"着順\"].map(clip_rank)\n",
    "results.drop([\"着順\", \"馬名\"], axis=1, inplace=True)\n",
    "\n",
    "#カテゴリ変数をダミー変数化\n",
    "results_d = pd.get_dummies(results)\n",
    "\n",
    "#訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = results_d.drop([\"rank\"], axis=1)\n",
    "y = results_d[\"rank\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "#アンダーサンプリング\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rank_1 = y_train.value_counts()[1]\n",
    "rank_2 = y_train.value_counts()[2]\n",
    "rank_3 = y_train.value_counts()[3]\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    #ratio={1: rank_1, 2: rank_2, 3: rank_3, 4: rank_1},\n",
    "    sampling_strategy={1: rank_1, 2: rank_2, 3: rank_3, 4: rank_1},\n",
    "    random_state=71\n",
    ")\n",
    "\n",
    "#X_train_rus, y_train_rus = rus.fit_sample(X_train.values, y_train.values)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train.values, y_train.values)\n",
    "\n",
    "#訓練\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "#スコアを表示\n",
    "print(model.score(X_train, y_train), model.score(X_test, y_test))\n",
    "\n",
    "#予測結果を確認\n",
    "y_pred = model.predict(X_test)\n",
    "pred_df = pd.DataFrame({\"pred\": y_pred, \"actual\": y_test})\n",
    "pred_df[pred_df[\"pred\"] == 1][\"actual\"].value_counts()\n",
    "\n",
    "#回帰係数の確認\n",
    "coefs = pd.Series(model.coef_[0], index=X.columns).sort_values()\n",
    "coefs[[\"枠番\", \"馬番\", \"斤量\", \"単勝\", \"人気\", \"年齢\", \"体重\", \"体重変化\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fee45",
   "metadata": {},
   "source": [
    "注意点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c247327",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle('results.pickle')\n",
    "results = preprocessing(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fce17b",
   "metadata": {},
   "source": [
    "# 第5回 BeautifulSoupで競馬データを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89868e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BSを使って\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "def scrape_race_info(race_id_list):\n",
    "    race_infos = {}\n",
    "    for race_id in tqdm(race_id_list):\n",
    "        try:\n",
    "            url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = (\n",
    "                soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[0].text\n",
    "                + soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[1].text\n",
    "            )\n",
    "            info = re.findall(r\"\\w+\", texts)\n",
    "            info_dict = {}\n",
    "            for text in info:\n",
    "                if text in [\"芝\", \"ダート\"]:\n",
    "                    info_dict[\"race_type\"] = text\n",
    "                if \"障\" in text:\n",
    "                    info_dict[\"race_type\"] = \"障害\"\n",
    "                if \"m\" in text:\n",
    "                    info_dict[\"course_len\"] = int(re.findall(r\"\\d+\", text)[0])\n",
    "                if text in [\"良\", \"稍重\", \"重\", \"不良\"]:\n",
    "                    info_dict[\"ground_state\"] = text\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    info_dict[\"weather\"] = text\n",
    "                if \"年\" in text:\n",
    "                    info_dict[\"date\"] = text\n",
    "            race_infos[race_id] = info_dict\n",
    "            time.sleep(1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "\texcept Exception as e:\n",
    "\t    print(e)\n",
    "\t    break\n",
    "        except:\n",
    "            break\n",
    "    return race_infos\n",
    "\n",
    "#前回保存したpickleファイルからデータ取得\n",
    "results = pd.read_pickle('results.pickle')\n",
    "\n",
    "#レースID一覧を取得してスクレイピング\n",
    "race_id_list = results.index.unique()\n",
    "race_infos = scrape_race_info(race_id_list)\n",
    "\n",
    "#DataFrame型にする\n",
    "race_infos = pd.DataFrame(race_infos).T\n",
    "\n",
    "#resultsに結合\n",
    "results_addinfo = results.merge(race_infos, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "#date列の処理を追加\n",
    "def preprocessing(results):\n",
    "    df = results.copy()\n",
    "\n",
    "    # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "    df = df[~(df[\"着順\"].astype(str).str.contains(\"\\D\"))]\n",
    "    df[\"着順\"] = df[\"着順\"].astype(int)\n",
    "\n",
    "    # 性齢を性と年齢に分ける\n",
    "    df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "    df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "    # 馬体重を体重と体重変化に分ける\n",
    "    df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "    df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "\n",
    "    # データをint, floatに変換\n",
    "    df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "\n",
    "    # 不要な列を削除\n",
    "    df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\"], axis=1, inplace=True)\n",
    "    \n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "    return df\n",
    "\n",
    "#前処理\n",
    "results_p = preprocessing(results_addinfo)\n",
    "\n",
    "#時系列に沿ってデータを分割\n",
    "def split_data(df, test_size):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]\n",
    "    test = df.loc[test_id_list]\n",
    "    return train, test\n",
    "\n",
    "results_p.drop([\"馬名\"], axis=1, inplace=True)\n",
    "results_d = pd.get_dummies(results_p)\n",
    "results_d[\"rank\"] = results_d[\"着順\"].map(lambda x: x if x < 4 else 4)\n",
    "train, test = split_data(results_d, test_size=0.3)\n",
    "X_train = train.drop([\"着順\", \"date\", \"rank\"], axis=1)\n",
    "y_train = train[\"rank\"]\n",
    "X_test = test.drop([\"着順\", \"date\", \"rank\"], axis=1)\n",
    "y_test = test[\"rank\"]\n",
    "\n",
    "#アンダーサンプリング\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rank_1 = train[\"rank\"].value_counts()[1]\n",
    "rank_2 = train[\"rank\"].value_counts()[2]\n",
    "rank_3 = train[\"rank\"].value_counts()[3]\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy={1: rank_1, 2: rank_2, 3: rank_3, 4: rank_1}, random_state=71\n",
    ")\n",
    "\n",
    "X_train_rus, y_train_rus = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "#ランダムフォレストによる予測\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train_rus, y_train_rus)\n",
    "print(clf.score(X_train, y_train), clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95441c6c",
   "metadata": {},
   "source": [
    "# 第6回 lightgbm・ランダムフォレストで競馬予想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d135be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#上で保存したpickleファイルの読み込み\n",
    "results = pd.read_pickle('results.pickle')\n",
    "\n",
    "#前処理\n",
    "results_p = preprocessing(results)\n",
    "\n",
    "#着順を0or1にする\n",
    "results_p['rank'] = results_p['着順'].map(lambda x: 1 if x<4 else 0)\n",
    "results_p.drop(['着順'], axis=1, inplace=True)\n",
    "\n",
    "#もし、動画のように着順をdropしてrankを作っている場合は\n",
    "results_p['rank'] = results_p['rank'].map(lambda x: 1 if x<4 else 0)\n",
    "\n",
    "#ランダムフォレストによる予測モデル作成\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#ROC曲線の表示\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#jupyterlabを使う場合、この2行はいらない\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme=\"monokai\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, marker=\"o\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#AUCスコアの表示\n",
    "roc_auc_score(y_test, y_pred)\n",
    "y_pred_train = rf.predict_proba(X_train)[:, 1]\n",
    "roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "#パラメータの調整\n",
    "params = {\n",
    "    \"min_samples_split\": 500,\n",
    "    \"max_depth\": None,\n",
    "    \"n_estimators\": 60,\n",
    "    \"criterion\": \"entropy\",\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 100,\n",
    "}\n",
    "rf = RandomForestClassifier(**params)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_train = rf.predict_proba(X_train)[:, 1]\n",
    "y_pred = rf.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_train, y_pred_train))\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#変数の重要度の表示\n",
    "importances = pd.DataFrame(\n",
    "    {\"features\": X_train.columns, \"importance\": rf.feature_importances_}\n",
    ")\n",
    "importances.sort_values(\"importance\", ascending=False)[:20]\n",
    "\n",
    "#LightGBMによる予測モデル作成\n",
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "    \"num_leaves\": 4,\n",
    "    \"n_estimators\": 80,\n",
    "    #'min_data_in_leaf': 15,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 100,\n",
    "}\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(X_train.values, y_train.values)\n",
    "y_pred_train = lgb_clf.predict_proba(X_train)[:, 1]\n",
    "y_pred = lgb_clf.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_train, y_pred_train))\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#変数の重要度の表示\n",
    "importances = pd.DataFrame(\n",
    "    {\"features\": X_train.columns, \"importance\": lgb_clf.feature_importances_}\n",
    ")\n",
    "importances.sort_values(\"importance\", ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5c3cc",
   "metadata": {},
   "source": [
    "# 第7回 Pythonで過去成績データをスクレイピングする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d73b5",
   "metadata": {},
   "source": [
    "scrape_race_results関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0367b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_race_results(race_id_list):   \n",
    "    #race_idをkeyにしてDataFrame型を格納\n",
    "    race_results = {}\n",
    "    for race_id in tqdm(race_id_list):\n",
    "        try:\n",
    "            url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\t    time.sleep(1)\n",
    "\t    #メインとなるテーブルデータを取得\n",
    "            df = pd.read_html(url)[0]\n",
    "            \n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "            \n",
    "            #馬ID、騎手IDをスクレイピング\n",
    "            horse_id_list = []\n",
    "            horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "            )\n",
    "            for a in horse_a_list:\n",
    "                horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                horse_id_list.append(horse_id[0])\n",
    "            jockey_id_list = []\n",
    "            jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "            )\n",
    "            for a in jockey_a_list:\n",
    "                jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                jockey_id_list.append(jockey_id[0])\n",
    "            df[\"horse_id\"] = horse_id_list\n",
    "            df[\"jockey_id\"] = jockey_id_list\n",
    "            \n",
    "            race_results[race_id] = df\n",
    "\t#存在しないrace_idを飛ばす\n",
    "        except IndexError:\n",
    "            continue\n",
    "\t#wifiの接続が切れた時などでも途中までのデータを返せるようにする\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\t#Jupyterで停止ボタンを押した時の対処    \n",
    "\texcept:\n",
    "\t    break\n",
    "    \n",
    "    return race_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#スクレイピング実行\n",
    "race_results = scrape_race_results(race_id_list)\n",
    "\n",
    "#indexをrace_idにする\n",
    "for key in race_results:\n",
    "    race_results[key].index = [key] * len(race_results[key])\n",
    "\n",
    "#pd.DataFrame型にして一つのデータにまとめる\n",
    "race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "#race_infosをmerge\n",
    "results = race_results_df.merge(race_infos, left_index=True,\n",
    "    right_index=True, how='left')\n",
    "    \n",
    "#pickleファイルに保存\n",
    "results.to_pickle('results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c02a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##scrape_horse_results関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ac07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_horse_results(horse_id_list):\n",
    "    #horse_idをkeyにしてDataFrame型を格納\n",
    "    horse_results = {}\n",
    "    for horse_id in tqdm(horse_id_list):\n",
    "        try:\n",
    "            url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "            df = pd.read_html(url)[3]\n",
    "\t    #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "            if df.columns[0]=='受賞歴':\n",
    "                df = pd.read_html(url)[4]\n",
    "            horse_results[horse_id] = df\n",
    "            time.sleep(1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    return horse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ed521",
   "metadata": {},
   "outputs": [],
   "source": [
    "###インデックスをhorse_idにする\n",
    "for key in horse_results:\n",
    "    horse_results[key].index = [key] * len(horse_results[key])\n",
    "    \n",
    "#一つのDataFrame型のデータにまとめる。\n",
    "horse_results = pd.concat([horse_results[key] for key in horse_results])\n",
    "\n",
    "#pickleファイルに保存\n",
    "horse_results.to_pickle('horse_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299bd21",
   "metadata": {},
   "source": [
    "# 第8回 競馬予想AIで学ぶクラス定義・オブジェクト志向"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5e601",
   "metadata": {},
   "source": [
    "HorseResultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f883048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金']]\n",
    "        self.preprocessing()\n",
    "        self.horse_results.rename(columns={'着順':'着順_ave', '賞金':'賞金_ave'}, \n",
    "\tinplace=True)\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "    \n",
    "        self.horse_results = df\n",
    "        \n",
    "    def average(self, horse_id_list, date):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        return target_df[target_df['date']<date].groupby(level=0)[['着順_ave', '賞金_ave']].mean()\n",
    "    \n",
    "    def merge(self, results, date):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        merged_df = df.merge(self.average(horse_id_list, date), left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat([self.merge(results, date) for date in tqdm(date_list)])\n",
    "        return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d0c00",
   "metadata": {},
   "source": [
    "# 第9回 データ加工で競馬予想AIの精度を上げる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf44f5",
   "metadata": {},
   "source": [
    "HorseResultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金']]\n",
    "        self.preprocessing()\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "    \n",
    "        self.horse_results = df\n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "            \n",
    "        average = filtered_df.groupby(level=0)[['着順', '賞金']].mean()\n",
    "        return average.rename(columns={'着順':'着順_{}R'.format(n_samples), '賞金':'賞金_{}R'.format(n_samples)})\n",
    "    \n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        merged_df = df.merge(self.average(horse_id_list, date, n_samples), left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat([self.merge(results, date, n_samples) for date in tqdm(date_list)])\n",
    "        return merged_df\n",
    "\n",
    "#HorseResultsクラスを使って過去成績データを結合\n",
    "hr = HorseResults(horse_results)\n",
    "results_5R = hr.merge_all(results_p, n_samples=5)\n",
    "results_5R['rank'] = results_5R['着順'].map(lambda x: 1 if x<4 else 0)\n",
    "results_5R.drop(['着順', '騎手', 'horse_id', '馬名'], axis=1, inplace=True)\n",
    "results_d = pd.get_dummies(results_5R)\n",
    "\n",
    "#訓練データとテストデータに分ける\n",
    "train, test = split_data(results_d)\n",
    "X_train = train.drop(['rank'], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop(['rank'], axis=1)\n",
    "y_test = test['rank']\n",
    "\n",
    "#LightGBMで学習\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "params = {\n",
    "    \"num_leaves\": 4,\n",
    "    \"n_estimators\": 80,\n",
    "    #'min_data_in_leaf': 15,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 100,\n",
    "}\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(X_train.values, y_train.values)\n",
    "y_pred_train = lgb_clf.predict_proba(X_train)[:, 1]\n",
    "y_pred = lgb_clf.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_train, y_pred_train))\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "#変数の重要度を出力\n",
    "importances = pd.DataFrame(\n",
    "    {\"features\": X_train.columns, \"importance\": lgb_clf.feature_importances_}\n",
    ")\n",
    "importances.sort_values(\"importance\", ascending=False)[:20] #jupyterで出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc13c3",
   "metadata": {},
   "source": [
    "# 第10回 競馬予想AIの回収率をシミュレーションする方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09e444",
   "metadata": {},
   "source": [
    "scrape_return_tables関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_return_tables(race_id_list, pre_return_rables={}):\n",
    "    return_tables = pre_return_tables\n",
    "    for race_id in tqdm(race_id_list):\n",
    "        try:\n",
    "            url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "            \n",
    "            #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "            #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "            f = urlopen(url)\n",
    "            html = f.read()\n",
    "            html = html.replace(b'<br />', b'br')\n",
    "            dfs = pd.read_html(html)\n",
    "\n",
    "            #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "            df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            return_tables[race_id] = df\n",
    "            time.sleep(1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except Exception as e: #捕捉できるエラーは原因がわかるようにprintしてからbreak\n",
    "            print(e)\n",
    "            break\n",
    "        except:\n",
    "            break\n",
    "    return return_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16b5fc",
   "metadata": {},
   "source": [
    "Returnクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4703ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    @property\n",
    "    def fukusho(self):\n",
    "        fukusho = self.return_tables[self.return_tables[0]=='複勝'][[1,2]]\n",
    "        #wins = fukusho[1].str.split('br', expand=True).drop([3], axis=1)\n",
    "        #5列できてしまう場合があるので、現在はこちらを推奨\n",
    "        wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        \n",
    "        wins.columns = ['win_0', 'win_1', 'win_2']\n",
    "        #returns = fukusho[2].str.split('br', expand=True).drop([3], axis=1)\n",
    "        #5列できてしまう場合があるので、現在はこちらを推奨\n",
    "        returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        returns.columns = ['return_0', 'return_1', 'return_2']\n",
    "        \n",
    "        df = pd.concat([wins, returns], axis=1)\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].str.replace(',', '')\n",
    "        return df.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3b353",
   "metadata": {},
   "source": [
    "ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ed7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables):\n",
    "        self.model = model\n",
    "        self.fukusho = Return(return_tables).fukusho\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "    \n",
    "    def score(self, y_true, X):\n",
    "        return roc_auc_score(y_true, self.predict_proba(X))\n",
    "    \n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                    \"importance\": self.model.feature_importances_})\n",
    "        return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "    \n",
    "    def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "        pred_table = X.copy()[['馬番']]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        if bet_only:\n",
    "            return pred_table[pred_table['pred']==1]['馬番']\n",
    "        else:\n",
    "            return pred_table\n",
    "        \n",
    "    def calculate_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        money = -100 * len(pred_table)\n",
    "        df = self.fukusho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        for i in range(3):\n",
    "            money += df[df['win_{}'.format(i)]==df['馬番']]['return_{}'.format(i)].sum()\n",
    "        return money"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05722c71",
   "metadata": {},
   "source": [
    "シミュレーション実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = {}\n",
    "n_samples = 100\n",
    "for i in tqdm(range(n_samples)):\n",
    "    threshold = i / n_samples\n",
    "    gain[threshold] = me.calculate_return(X_test, threshold)\n",
    "    \n",
    "#プロット\n",
    "pd.Series(gain).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168196a8",
   "metadata": {},
   "source": [
    "注意点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in return_tables.keys():\n",
    "    return_tables[key].index = [key]*len(return_tables[key])\n",
    "    \n",
    "return_tables = pd.concat([return_tables[key] for key in return_tables.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac035f6",
   "metadata": {},
   "source": [
    "# 第11回 Pythonで過去成績を入れた出馬表を作る方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429fecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "class ShutubaTable:\n",
    "    def __init__(self):\n",
    "        self.shutuba_table = pd.DataFrame()\n",
    "    \n",
    "    def scrape_shutuba_table(self, race_id_list):\n",
    "        options = ChromeOptions()\n",
    "        driver = Chrome(options=options)\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            driver.get(url)\n",
    "            elements = driver.find_elements_by_class_name('HorseList')\n",
    "            for element in elements:\n",
    "                tds = element.find_elements_by_tag_name('td')\n",
    "                row = []\n",
    "                for td in tds:\n",
    "                    row.append(td.text)\n",
    "                    if td.get_attribute('class') in ['HorseInfo', 'Jockey']:\n",
    "                        href = td.find_element_by_tag_name('a').get_attribute('href')\n",
    "                        row.append(re.findall(r'\\d+', href)[0])\n",
    "                self.shutuba_table = self.shutuba_table.append(pd.Series(row, name=race_id))\n",
    "            time.sleep(1)\n",
    "        driver.close()\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.shutuba_table.copy()\n",
    "        df = df[[0,1,3,4,5,6,7,8,10,11,12]]\n",
    "        df.columns = ['枠番', '馬番', '馬名', 'horse_id', '性齢', '斤量', '騎手', 'jockey_id',\n",
    "                      '馬体重', '単勝', '人気']\n",
    "        self.shutuba_table = df\n",
    "        \n",
    "    def merge_horse_results(self, horse_results, columns, n_race=5):\n",
    "        for column in columns:\n",
    "            df = horse_results.groupby(level=0).head(n_race)\n",
    "            df = df.astype(str).groupby(level=0)[column].apply(lambda x: ','.join(x))\n",
    "            df = df.str.split(',', expand=True).add_prefix('{}_'.format(column))\n",
    "            self.shutuba_table = self.shutuba_table.merge(df, left_on='horse_id',\n",
    "                                                          right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58288dd",
   "metadata": {},
   "source": [
    "# 第12回 LightGBMに競馬の血統データを入れる方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a342f",
   "metadata": {},
   "source": [
    "scrape_peds関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_peds(horse_id_list, pre_peds = {}):\n",
    "    peds = pre_peds\n",
    "    for horse_id in tqdm(horse_id_list):\n",
    "        try:\n",
    "            url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "            df = pd.read_html(url)[0]\n",
    "\n",
    "            #重複を削除して1列のSeries型データに直す\n",
    "            generations = {}\n",
    "            for i in reversed(range(5)):\n",
    "                generations[i] = df[i]\n",
    "                df.drop([i], axis=1, inplace=True)\n",
    "                df = df.drop_duplicates()\n",
    "            ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "\n",
    "            peds[horse_id] = ped.reset_index(drop=True)\n",
    "            time.sleep(1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "        except:\n",
    "            break\n",
    "    return peds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537780c",
   "metadata": {},
   "source": [
    "注意点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in peds:\n",
    "    return_tables[key].index = [key]*len(return_tables[key])\n",
    "    \n",
    "peds = pd.concat([peds[key] for key in peds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8561a0",
   "metadata": {},
   "source": [
    "処理実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68448431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ読み込み&前処理\n",
    "results = pd.read_pickle('results.pickle')\n",
    "horse_results = pd.read_pickle('horse_results.pickle')\n",
    "results_p = preprocessing(results)\n",
    "hr = HorseResults(horse_results)\n",
    "results_m = hr.merge_all(results_p, n_samples=5)\n",
    "results_m['rank'] = results_m['着順'].map(lambda x:1 if x<4 else 0)\n",
    "results_m.drop(['着順'], axis=1, inplace=True)\n",
    "\n",
    "#horse_idをラベルエンコーディング\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "results_m['horse_id'] = LabelEncoder().fit_transform(results_m['horse_id'])\n",
    "\n",
    "#ダミー変数化\n",
    "results_d = pd.get_dummies(results_m)\n",
    "\n",
    "#horse_idをpandasのcategory型に変換\n",
    "results_d['horse_id'] = results_d['horse_id'].astype('category')\n",
    "\n",
    "#LightGBMで学習\n",
    "import lightgbm as lgb\n",
    "\n",
    "train, test = split_data(results_d)\n",
    "X_train = train.drop(['rank'], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop(['rank'], axis=1)\n",
    "y_test = test['rank']\n",
    "params = {\n",
    "    \"num_leaves\": 4,\n",
    "    \"n_estimators\": 80,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 100,\n",
    "}\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "#特徴量の重要度を表示\n",
    "return_tables = pd.read_pickle('return_tables.pickle')\n",
    "me = ModelEvaluator(lgb_clf, return_tables)\n",
    "me.feature_importance(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90d2a1",
   "metadata": {},
   "source": [
    "# 第13回 競馬予想AIの回収率を上げた意外な方法とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc7a4e",
   "metadata": {},
   "source": [
    "process_categorical関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical(df, target_columns):\n",
    "    df2 = df.copy()\n",
    "    for column in target_columns:\n",
    "        df2[column] = LabelEncoder().fit_transform(df2[column].fillna('Na'))\n",
    "    \n",
    "    #target_columns以外にカテゴリ変数があれば、ダミー変数にする\n",
    "    df2 = pd.get_dummies(df2)\n",
    "    \n",
    "    for column in target_columns:\n",
    "        df2[column] = df2[column].astype('category')\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['horse_id'] + peds.columns\n",
    "results_d = process_categorical(results_m, categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07613e",
   "metadata": {},
   "source": [
    "gain関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33640bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(return_func, X, n_samples=100, lower=50, min_threshold=0.5):\n",
    "    gain = {}\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        threshold = 1 * i / n_samples + min_threshold * (1-(i/n_samples))\n",
    "        n_bets, money = return_func(X, threshold)\n",
    "        if n_bets > lower:\n",
    "            gain[n_bets] = (n_bets*100 + money) / (n_bets*100)\n",
    "    return pd.Series(gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f01ac",
   "metadata": {},
   "source": [
    "Returnクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    @property\n",
    "    def fukusho(self):\n",
    "        fukusho = self.return_tables[self.return_tables[0]=='複勝'][[1,2]]\n",
    "        #wins = fukusho[1].str.split('br', expand=True).drop([3], axis=1)\n",
    "        #5列できてしまう場合があるので、現在はこちらを推奨\n",
    "        wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        \n",
    "        wins.columns = ['win_0', 'win_1', 'win_2']\n",
    "        #returns = fukusho[2].str.split('br', expand=True).drop([3], axis=1)\n",
    "        #5列できてしまう場合があるので、現在はこちらを推奨\n",
    "        returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        returns.columns = ['return_0', 'return_1', 'return_2']\n",
    "        \n",
    "        df = pd.concat([wins, returns], axis=1)\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].str.replace(',', '')\n",
    "        return df.fillna(0).astype(int)\n",
    "\n",
    "    @property\n",
    "    def tansho(self):\n",
    "        tansho = self.return_tables[self.return_tables[0]=='単勝'][[1,2]]\n",
    "        tansho.columns = ['win', 'return']\n",
    "        \n",
    "        for column in tansho.columns:\n",
    "            tansho[column] = pd.to_numeric(tansho[column], errors='coerce')\n",
    "            \n",
    "        return tansho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b55514",
   "metadata": {},
   "source": [
    "ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables):\n",
    "        self.model = model\n",
    "        self.fukusho = Return(return_tables).fukusho\n",
    "        self.tansho = Return(return_tables).tansho\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        proba = pd.Series(self.model.predict_proba(X)[:, 1], index=X.index)\n",
    "        return proba\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "    \n",
    "    def score(self, y_true, X):\n",
    "        return roc_auc_score(y_true, self.predict_proba(X))\n",
    "    \n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                    \"importance\": self.model.feature_importances_})\n",
    "        return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "    \n",
    "    def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "        pred_table = X.copy()[['馬番']]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        if bet_only:\n",
    "            return pred_table[pred_table['pred']==1]['馬番']\n",
    "        else:\n",
    "            return pred_table\n",
    "        \n",
    "    def fukusho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        money = -100 * n_bets\n",
    "        df = self.fukusho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        for i in range(3):\n",
    "            money += df[df['win_{}'.format(i)]==df['馬番']]['return_{}'.format(i)].sum()\n",
    "        return n_bets, money\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        money = -100 * n_bets\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        money += df[df['win']==df['馬番']]['return'].sum()\n",
    "        return n_bets, money    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
