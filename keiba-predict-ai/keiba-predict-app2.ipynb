{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1cab8",
   "metadata": {},
   "source": [
    "# 第14回 Pythonで単勝回収率122%の競馬予想AIを作る方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c4d71",
   "metadata": {},
   "source": [
    "predict_proba関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(self, X):\n",
    "    proba = pd.Series(self.model.predict_proba(X)[:, 1], index=X.index)\n",
    "    if self.std:\n",
    "\tstandard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "\tproba = proba.groupby(level=0).transform(standard_scaler)\n",
    "\tproba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d262a",
   "metadata": {},
   "source": [
    "# 第15回〜第18回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2004a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(old, new):\n",
    "filtered_old = old[~old.index.isin(new.index)]\n",
    "    return pd.concat([filtered_old, new])\n",
    "\n",
    "class ShutubaTable:\n",
    "    def __init__(self):\n",
    "        self.shutuba_tables = pd.DataFrame()\n",
    "        self.shutuba_tables_p = pd.DataFrame() #after preprocessing\n",
    "        self.shutuba_tables_h = pd.DataFrame() #after merging horse_results\n",
    "        self.shutuba_tables_pe = pd.DataFrame() #after merging peds\n",
    "        self.shutuba_tables_c = pd.DataFrame() #after processing categorical features\n",
    "    \n",
    "    def scrape(self, race_id_list, date):\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "            texts = re.findall(r'\\w+', texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "\n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = horse_id_list\n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            self.shutuba_tables = self.shutuba_tables.append(df)\n",
    "            time.sleep(1)\n",
    "                \n",
    "    def preprocessing(self):\n",
    "        df = self.shutuba_tables.copy()\n",
    "        \n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df = df[df[\"馬体重(増減)\"] != '--']\n",
    "        df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        df['枠'] = df['枠'].astype(int)\n",
    "        df['馬番'] = df['馬番'].astype(int)\n",
    "        df['斤量'] = df['斤量'].astype(int)\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df = df[['枠', '馬番', '斤量', 'course_len', 'weather','race_type',\n",
    "        'ground_state', 'date', 'horse_id', 'jockey_id', '性', '年齢',\n",
    "       '体重', '体重変化']]\n",
    "        \n",
    "        self.shutuba_tables_p = df.rename(columns={'枠': '枠番'})\n",
    "        \n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        self.shutuba_tables_h = self.shutuba_tables_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.shutuba_tables_h = hr.merge_all(self.shutuba_tables_h, n_samples=n_samples)\n",
    "            \n",
    "    def merge_peds(self, peds):\n",
    "        self.shutuba_tables_pe = self.shutuba_tables_h.merge(peds,left_on='horse_id',\n",
    "\tright_index=True, how='left')\n",
    "        self.no_peds = self.shutuba_tables_pe[self.shutuba_tables_pe['peds_0'].isnull()]\\\n",
    "            ['horse_id'].unique()\n",
    "        if len(self.no_peds) > 0:\n",
    "            print('scrape peds at horse_id_list \"no_peds\"')\n",
    "            \n",
    "    def process_categorical(self, le_horse, le_jockey, results_m):\n",
    "        df = self.shutuba_tables_pe.copy()\n",
    "        \n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        \n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "        \n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        \n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        \n",
    "        self.shutuba_tables_c = df\n",
    "\n",
    "class Peds:\n",
    "    def __init__(self, peds):\n",
    "        self.peds = peds\n",
    "        self.peds_e = pd.DataFrame() #after label encoding and transforming into category\n",
    "    \n",
    "    def encode(self):\n",
    "        df = self.peds.copy()\n",
    "        for column in df.columns:\n",
    "            df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "        self.peds_e = df.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d310a",
   "metadata": {},
   "source": [
    "# 概要（第19回）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125ade9",
   "metadata": {},
   "source": [
    "第19回では、競馬予想AIに必要なデータ加工を、次の3つのクラスにまとめます。\n",
    "\n",
    "・Resultsクラス・・・レース結果データを加工するクラス\n",
    "\n",
    "・ShutubaTableクラス・・・実際に賭ける時に使う出馬表データを加工するクラス\n",
    "\n",
    "・DataProcessorクラス・・・上2つに共通する処理をまとめる抽象クラス\n",
    "\n",
    "この動画以降、基本的にデータ加工はこの3つのクラスを使って進めることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3d089",
   "metadata": {},
   "source": [
    "DataProcessorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame() #raw data\n",
    "        self.data_p = pd.DataFrame() #after preprocessing\n",
    "        self.data_h = pd.DataFrame() #after merging horse_results\n",
    "        self.data_pe = pd.DataFrame() #after merging peds\n",
    "        self.data_c = pd.DataFrame() #after processing categorical features\n",
    "        \n",
    "    #馬の過去成績データの追加\n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        self.data_h = self.data_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.data_h = hr.merge_all(self.data_h, n_samples=n_samples)\n",
    "            \n",
    "    #血統データ追加\n",
    "    def merge_peds(self, peds):\n",
    "        self.data_pe = \\\n",
    "            self.data_h.merge(peds, left_on='horse_id', right_index=True,\n",
    "                                                             how='left')\n",
    "        self.no_peds = self.data_pe[self.data_pe['peds_0'].isnull()]\\\n",
    "            ['horse_id'].unique()\n",
    "        if len(self.no_peds) > 0:\n",
    "            print('scrape peds at horse_id_list \"no_peds\"')\n",
    "            \n",
    "        #カテゴリ変数の処理\n",
    "    def process_categorical(self, le_horse, le_jockey, results_m):\n",
    "        df = self.data_pe.copy()\n",
    "        \n",
    "        #ラベルエンコーディング。horse_id, jockey_idを0始まりの整数に変換\n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "        \n",
    "        #horse_id, jockey_idをpandasのcategory型に変換\n",
    "        df['horse_id'] = df['horse_id'].astype('category')\n",
    "        df['jockey_id'] = df['jockey_id'].astype('category')\n",
    "        \n",
    "        #そのほかのカテゴリ変数をpandasのcategory型に変換してからダミー変数化\n",
    "        #列を一定にするため\n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        \n",
    "        self.data_c = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f26661c",
   "metadata": {},
   "source": [
    "ShutubaTableクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShutubaTable(DataProcessor):\n",
    "    def __init__(self):\n",
    "        super(ShutubaTable, self).__init__()\n",
    "    \n",
    "    def scrape(self, race_id_list, date):\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "            texts = re.findall(r'\\w+', texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "\n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = horse_id_list\n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            self.data = self.data.append(df)\n",
    "            time.sleep(1)\n",
    "                \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df = df[df[\"馬体重(増減)\"] != '--']\n",
    "        df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        df['枠'] = df['枠'].astype(int)\n",
    "        df['馬番'] = df['馬番'].astype(int)\n",
    "        df['斤量'] = df['斤量'].astype(int)\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df = df[['枠', '馬番', '斤量', 'course_len', 'weather','race_type',\n",
    "        'ground_state', 'date', 'horse_id', 'jockey_id', '性', '年齢',\n",
    "       '体重', '体重変化']]\n",
    "        \n",
    "        self.data_p = df.rename(columns={'枠': '枠番'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5adc2ac",
   "metadata": {},
   "source": [
    "Resultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf422b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    #前処理    \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "        df['rank'] = df['着順'].map(lambda x:1 if x<4 else 0)\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "\n",
    "        # データをint, floatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        df[\"course_len\"] = df[\"course_len\"].astype(float)\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名', '騎手', '単勝', '人気', '着順'],\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "\n",
    "        self.data_p = df\n",
    "    \n",
    "    #カテゴリ変数の処理\n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "        super().process_categorical(self.le_horse, self.le_jockey, self.data_pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aadc5d",
   "metadata": {},
   "source": [
    "実行方法\n",
    "レース結果データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultsクラスのオブジェクト作成\n",
    "r = Results(results)\n",
    "\n",
    "#前処理\n",
    "r.preprocessing()\n",
    "\n",
    "#馬の過去成績データ追加\n",
    "hr = HorseResults(horse_results)\n",
    "r.merge_horse_results(hr)\n",
    "\n",
    "#血統データ追加\n",
    "p = Peds(peds)\n",
    "p.encode()\n",
    "r.merge_peds(p.peds_e)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "r.process_categorical()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ab17e",
   "metadata": {},
   "source": [
    "出馬表データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188efc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#スクレイピング\n",
    "race_id_list = ['2020010106{}'.format(str(i).zfill(2)) for i in range(1,13)]\n",
    "st = ShutubaTable()\n",
    "st.scrape(race_id_list, '2020/08/09')\n",
    "\n",
    "#前処理\n",
    "st.preprocessing()\n",
    "\n",
    "#馬の過去成績データ追加\n",
    "st.merge_horse_results(hr)\n",
    "\n",
    "#血統データ追加\n",
    "st.merge_peds(p.peds_e)\n",
    "\n",
    "#カテゴリ変数の処理\n",
    "st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e11964",
   "metadata": {},
   "source": [
    "実際に賭ける方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#本番なので、全データを使う\n",
    "X = r.data_c.drop(['rank', 'date'], axis = 1)\n",
    "y = r.data_c['rank']\n",
    "\n",
    "#訓練\n",
    "params = {\n",
    "    \"num_leaves\": 4,\n",
    "    \"n_estimators\": 80,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 100,\n",
    "}\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(X.values, y.values)\n",
    "\n",
    "#ModelEvaluatorに入れる\n",
    "return_tables = pd.read_pickle('return_tables.pickle')\n",
    "me = ModelEvaluator(lgb_clf, return_tables)\n",
    "\n",
    "#予測\n",
    "pred = me.predict_proba(st.data_c.drop(['date'], axis=1))\n",
    "pred_table = st.data_c[['馬番']].copy()\n",
    "pred_table['pred'] = pred\n",
    "pred_table.sort_values('pred', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91a784",
   "metadata": {},
   "source": [
    "# 概要（第20回）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fcbef",
   "metadata": {},
   "source": [
    "ModelEvaluatorクラスに単勝適正回収値という賭け方を実装します。\n",
    "単勝適正回収値とは、「払い戻し金額を常に一定にするように賭ける」賭け方のことです。これによって、単勝回収率がオッズの高い馬に引っ張られてしまうのを防ぎます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478e390",
   "metadata": {},
   "source": [
    "ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a53f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables, std=True):\n",
    "        self.model = model\n",
    "        self.fukusho = Return(return_tables).fukusho\n",
    "        self.tansho = Return(return_tables).tansho\n",
    "        self.std = std\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        proba = pd.Series(self.model.predict_proba(X)[:, 1], index=X.index)\n",
    "        if self.std:\n",
    "            #標準化： レース内で相対評価する\n",
    "            standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "            proba = proba.groupby(level=0).transform(standard_scaler)\n",
    "        proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "        return proba\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "    \n",
    "    def score(self, y_true, X):\n",
    "        return roc_auc_score(y_true, self.predict_proba(X))\n",
    "    \n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                    \"importance\": self.model.feature_importances_})\n",
    "        return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "    \n",
    "    def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "        pred_table = X.copy()[['馬番']]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        if bet_only:\n",
    "            return pred_table[pred_table['pred']==1]['馬番']\n",
    "        else:\n",
    "            return pred_table\n",
    "        \n",
    "    def fukusho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        money = -100 * n_bets\n",
    "        df = self.fukusho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        for i in range(3):\n",
    "            money += df[df['win_{}'.format(i)]==df['馬番']]['return_{}'.format(i)].sum()\n",
    "        return_rate = (n_bets*100 + money) / (n_bets*100)\n",
    "        return n_bets, return_rate\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        money = -100 * n_bets\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        money += df[df['win']==df['馬番']]['return'].sum()\n",
    "        return_rate = (n_bets*100 + money) / (n_bets*100)\n",
    "        return n_bets, return_rate\n",
    "    \n",
    "    def tansho_return_proper(self, X, threshold=0.5):\n",
    "        #モデルによって「賭ける」と判断された馬たち\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        #払い戻し表にpred_tableをマージ\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        \n",
    "        #単勝適正回収値を計算\n",
    "        return_rate = len(df.query('win == 馬番')) / (100 / df['return']).sum()\n",
    "        \n",
    "        return n_bets, return_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a82a2e",
   "metadata": {},
   "source": [
    "gain関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(return_func, X, n_samples=100, lower=50, min_threshold=0.5):\n",
    "    gain = {}\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        threshold = 1 * i / n_samples + min_threshold * (1-(i/n_samples))\n",
    "        n_bets, return_rate = return_func(X, threshold)\n",
    "        if n_bets > lower:\n",
    "            gain[n_bets] = return_rate\n",
    "    return pd.Series(gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb24860",
   "metadata": {},
   "source": [
    "注意点（重要）\n",
    "\n",
    "ModelEvaluator.tansho_return_proper()の以下の部分が間違っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rate = len(df.query('win == 馬番')) / (100 / df['return']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815fa6b",
   "metadata": {},
   "source": [
    "100 / df['return']が間違っていて、df['return']には単勝で勝った馬の払い戻し金額が入っているので、これだと払い戻し金額が一定になる賭け方になっていません。正しくはX_testから単勝の列を取ってきて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rate = len(df.query('win == 馬番')) / (1 / df['単勝']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a197c",
   "metadata": {},
   "source": [
    "としなければなりません。これに関しては、後の動画で修正します。\n",
    "\n",
    "↓参考（第27回）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
