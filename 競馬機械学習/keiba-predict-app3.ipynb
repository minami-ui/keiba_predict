{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9173f82",
   "metadata": {},
   "source": [
    "# 概要（第21回）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ce279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_size=0.3):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]#.drop(['date'], axis=1)\n",
    "    test = df.loc[test_id_list]#.drop(['date'], axis=1)\n",
    "    return train, test\n",
    "    \n",
    "train, test = split_data(r.data_c)\n",
    "train, valid = split_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7feb219",
   "metadata": {},
   "source": [
    "準備ができたら、実際にチューニングを実行します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f40042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb_o\n",
    "\n",
    "#説明変数と目的変数に分ける\n",
    "X_train = train.drop(['rank', 'date'], axis=1)\n",
    "y_train = train['rank']\n",
    "X_valid = valid.drop(['rank', 'date'], axis=1)\n",
    "y_valid = valid['rank']\n",
    "X_test = test.drop(['rank', 'date'], axis=1)\n",
    "y_test = test['rank']\n",
    "\n",
    "# データセットの作成\n",
    "lgb_train = lgb_o.Dataset(X_train.values, y_train.values)\n",
    "lgb_valid = lgb_o.Dataset(X_valid.values, y_valid.values)\n",
    "\n",
    "#チューニング実行\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'random_state': 100\n",
    "}\n",
    "\n",
    "lgb_clf_o = lgb_o.train(params, lgb_train,\n",
    "                        valid_sets=(lgb_train, lgb_valid),\n",
    "                        verbose_eval=100,\n",
    "                        early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0edf57",
   "metadata": {},
   "source": [
    "完了したら、実際にこのパラメータを使って訓練します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの分け方を元に戻す\n",
    "train, test = split_data(r.data_c)\n",
    "X_train = train.drop(['rank', 'date'], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop(['rank', 'date'], axis=1)\n",
    "y_test = test['rank']\n",
    "\n",
    "#訓練\n",
    "lgb_clf = lgb.LGBMClassifier(**lgb_clf_o.params)\n",
    "lgb_clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "#回収率シミュレーション\n",
    "me2 = ModelEvaluator(lgb_clf, return_tables)\n",
    "gain_optuna = gain(me2.tansho_return_proper, X_test)\n",
    "\n",
    "#回収率プロット\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(dpi = 100) #動画と違いますが、この方が軸の文字なども拡大されます\n",
    "gain_proper.rename('proper').plot()\n",
    "gain_optuna.rename('optuna').plot()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84b346",
   "metadata": {},
   "source": [
    "# 注意点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元々のパラメータ\n",
    "{\n",
    "    'objective': 'binary',\n",
    "    'random_state': 100,\n",
    "    'feature_pre_filter': False,\n",
    "    'lambda_l1': 0.00020915763049139397,\n",
    "    'lambda_l2': 0.0004315924345758067,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 0,\n",
    "    'min_child_samples': 100,\n",
    "    'num_iterations': 1000,\n",
    "    'early_stopping_round': 10\n",
    "}\n",
    "\n",
    "# 変更後\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'random_state': 100,\n",
    "    'feature_pre_filter': False,\n",
    "    'lambda_l1': 0.00020915763049139397,\n",
    "    'lambda_l2': 0.0004315924345758067,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 0,\n",
    "    'min_child_samples': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdca88ca",
   "metadata": {},
   "source": [
    "# 概要（第22回）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5006f-b540-4ca5-ae45-750f51f6c520",
   "metadata": {},
   "source": [
    " ## Resultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        #race_idをkeyにしてDataFrame型を格納\n",
    "        race_results = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "                #メインとなるテーブルデータを取得\n",
    "                df = pd.read_html(url)[0]\n",
    "\n",
    "                html = requests.get(url)\n",
    "                html.encoding = \"EUC-JP\"\n",
    "                soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "                #天候、レースの種類、コースの長さ、馬場の状態、日付をスクレイピング\n",
    "                texts = (\n",
    "                    soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[0].text\n",
    "                    + soup.find(\"div\", attrs={\"class\": \"data_intro\"}).find_all(\"p\")[1].text\n",
    "                )\n",
    "                info = re.findall(r'\\w+', texts)\n",
    "                for text in info:\n",
    "                    if text in [\"芝\", \"ダート\"]:\n",
    "                        df[\"race_type\"] = [text] * len(df)\n",
    "                    if \"障\" in text:\n",
    "                        df[\"race_type\"] = [\"障害\"] * len(df)\n",
    "                    if \"m\" in text:\n",
    "                        df[\"course_len\"] = [int(re.findall(r\"\\d+\", text)[0])] * len(df)\n",
    "                    if text in [\"良\", \"稍重\", \"重\", \"不良\"]:\n",
    "                        df[\"ground_state\"] = [text] * len(df)\n",
    "                    if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                        df[\"weather\"] = [text] * len(df)\n",
    "                    if \"年\" in text:\n",
    "                        df[\"date\"] = [text] * len(df)\n",
    "\n",
    "                #馬ID、騎手IDをスクレイピング\n",
    "                horse_id_list = []\n",
    "                horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "                )\n",
    "                for a in horse_a_list:\n",
    "                    horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    horse_id_list.append(horse_id[0])\n",
    "                jockey_id_list = []\n",
    "                jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "                )\n",
    "                for a in jockey_a_list:\n",
    "                    jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    jockey_id_list.append(jockey_id[0])\n",
    "                df[\"horse_id\"] = horse_id_list\n",
    "                df[\"jockey_id\"] = jockey_id_list\n",
    "\n",
    "                #インデックスをrace_idにする\n",
    "                df.index = [race_id] * len(df)\n",
    "\n",
    "                race_results[race_id] = df\n",
    "            #存在しないrace_idを飛ばす\n",
    "            except IndexError:\n",
    "                continue\n",
    "            #wifiの接続が切れた時などでも途中までのデータを返せるようにする\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            #Jupyterで停止ボタンを押した時の対処\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "        return race_results_df\n",
    "    \n",
    "    #以下省略 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e877e6-fad3-49ea-8002-9bdf5054f545",
   "metadata": {},
   "source": [
    "## HorseResultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef83e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金']]\n",
    "        self.preprocessing()\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        #horse_idをkeyにしてDataFrame型を格納\n",
    "        horse_results = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            try:\n",
    "                url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "                df = pd.read_html(url)[3]\n",
    "                #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "                if df.columns[0]=='受賞歴':\n",
    "                    df = pd.read_html(url)[4]\n",
    "                df.index = [horse_id] * len(df)\n",
    "                horse_results[horse_id] = df\n",
    "                time.sleep(1)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる        \n",
    "        horse_results_df = pd.concat([horse_results[key] for key in horse_results])\n",
    "\n",
    "        return horse_results_df\n",
    "    #以下省略    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af23e74-f00c-4598-9c07-647d51ae4548",
   "metadata": {},
   "source": [
    "## Pedsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11edd9-5633-4fda-b3cb-15c6452c112f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Peds:\n",
    "    def __init__(self, peds):\n",
    "        self.peds = peds\n",
    "        self.peds_e = pd.DataFrame() #after label encoding and transforming into category\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        peds_dict = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "                df = pd.read_html(url)[0]\n",
    "\n",
    "                #重複を削除して1列のSeries型データに直す\n",
    "                generations = {}\n",
    "                for i in reversed(range(5)):\n",
    "                    generations[i] = df[i]\n",
    "                    df.drop([i], axis=1, inplace=True)\n",
    "                    df = df.drop_duplicates()\n",
    "                ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "\n",
    "                peds_dict[horse_id] = ped.reset_index(drop=True)\n",
    "                time.sleep(1)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #列名をpeds_0, ..., peds_61にする\n",
    "        peds_df = pd.concat([peds_dict[key] for key in peds_dict],\n",
    "                            axis=1).T.add_prefix('peds_')\n",
    "\n",
    "        return peds_df\n",
    "    \n",
    "    def encode(self):\n",
    "        df = self.peds.copy()\n",
    "        for column in df.columns:\n",
    "            df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "        self.peds_e = df.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ba3ca-ede8-48db-bedd-c36bfeb8e6a8",
   "metadata": {},
   "source": [
    "## Returnクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ea70e-6436-4c4e-b88d-523a4d07da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "        \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "                #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "                f = urlopen(url)\n",
    "                html = f.read()\n",
    "                html = html.replace(b'<br />', b'br')\n",
    "                dfs = pd.read_html(html)\n",
    "\n",
    "                #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "                time.sleep(1)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        return return_tables_df\n",
    "    \n",
    "    #以下省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2b2e4-9311-4383-810c-8c6169165ac4",
   "metadata": {},
   "source": [
    "## ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa1526-2737-43ba-8361-f2566460e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables_path, std=True):\n",
    "        self.model = model\n",
    "        self.fukusho = Return.read_pickle([return_tables_path]).fukusho\n",
    "        self.tansho = Return.read_pickle([return_tables_path]).tansho\n",
    "        self.std = std\n",
    "    #以下省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3068c9-7a5e-4120-8ccb-0b21b381f97f",
   "metadata": {},
   "source": [
    "## ShutubaTableクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964d0ae-9377-4706-a8a1-ade03f41a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShutubaTable(DataProcessor):\n",
    "    def __init__(self, shutuba_tables):\n",
    "        super(ShutubaTable, self).__init__()\n",
    "        self.data = shutuba_tables\n",
    "    \n",
    "    @classmethod\n",
    "    def scrape(cls, race_id_list, date):\n",
    "        data = pd.DataFrame()\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "\n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "\n",
    "            texts = soup.find('div', attrs={'class': 'RaceData01'}).text\n",
    "            texts = re.findall(r'\\w+', texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "\n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = horse_id_list\n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            data = data.append(df)\n",
    "            time.sleep(1)\n",
    "        return data\n",
    "    #以下省略            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8ebff-ba91-4df9-a86f-02579022fd89",
   "metadata": {},
   "source": [
    "## 注意点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8f352-eed1-461e-b780-3b6e56559a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a31b4-a0da-4629-b822-b5babcb4008a",
   "metadata": {},
   "source": [
    "# 概要 第23回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc647a-2445-4aba-b7e0-dffe1e0ad1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過']]\n",
    "        self.preprocessing()\n",
    "    \n",
    "    #省略\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "    \n",
    "        self.horse_results = df\n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "            \n",
    "        average = filtered_df.groupby(level=0)[['着順', '賞金', '着差',\n",
    "                                               'first_corner', 'final_corner',\n",
    "                                               'final_to_rank', 'first_to_rank',\n",
    "                                               'first_to_final']].mean()\n",
    "        return average.rename(\n",
    "            columns={'着順':'着順_{}R'.format(n_samples),\n",
    "                     '賞金':'賞金_{}R'.format(n_samples),\n",
    "                     '着差':'着差_{}R'.format(n_samples),\n",
    "                     'first_corner':'first_corner_{}R'.format(n_samples),\n",
    "                     'final_corner':'final_corner_{}R'.format(n_samples),\n",
    "                     'final_to_rank':'final_to_rank_{}R'.format(n_samples),\n",
    "                     'first_to_rank':'first_to_rank_{}R'.format(n_samples),\n",
    "                     'first_to_final':'first_to_final_{}R'.format(n_samples)}\n",
    "        )\n",
    "    \n",
    "    #省略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f8ca5-0e14-4c11-bffa-cfd4d7a175cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rate = len(df.query('win == 馬番')) / (100 / df['return']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681fb592-7996-46bd-9b7a-888bf28884a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rate = len(df.query('win == 馬番')) / (1 / df['単勝']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e340bf1-c1e4-4a1f-97dd-1e7d73ffa371",
   "metadata": {},
   "source": [
    "# 概要　第24回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a983d-958a-4ce4-acdd-05096f0707bc",
   "metadata": {},
   "source": [
    "## Returnクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa27464d-344e-4320-bc50-b0b133abc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "        \n",
    "    #省略\n",
    "    \n",
    "    @property\n",
    "    def umaren(self):\n",
    "        umaren = self.return_tables[self.return_tables[0]=='馬連'][[1,2]]\n",
    "        wins = umaren[1].str.split('-', expand=True)[[0,1]].add_prefix('win_')\n",
    "        return_ = umaren[2].rename('return')  \n",
    "        df = pd.concat([wins, return_], axis=1)        \n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c0dee-f19b-463f-9872-a6598ebd0b34",
   "metadata": {},
   "source": [
    "## ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904a8c1-b3d6-45f0-ac6a-eb1db528596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#新しくインポートするパッケージ\n",
    "import scipy.special import comb\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables_path, std=True):\n",
    "        self.model = model\n",
    "        self.rt = Return.read_pickle([return_tables_path])\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.std = std\n",
    "    \n",
    "\t#省略\n",
    "    \n",
    "    def umaren_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        hit = {}\n",
    "        n_bets = 0\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            n_bets += comb(len(preds, 2))\n",
    "            hit[race_id] = set(\n",
    "                self.umaren.loc[race_id][['win_0', 'win_1']]\n",
    "            ).issubset(set(preds))\n",
    "        return_rate = self.umaren.index.map(hit).values * self.umaren['return'].sum() / \\\n",
    "            (n_bets * 100)\n",
    "        return n_bets, return_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d48629-88f6-40ee-8268-b95fd31bff1d",
   "metadata": {},
   "source": [
    "# 概要 第25回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905b0bc-cb07-45f9-a5ce-788e14f3e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過',\n",
    "                                            '開催', '距離']]\n",
    "        self.preprocessing()\n",
    "    \n",
    "    # 省略\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "        #race_type\n",
    "        df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "        #距離\n",
    "        df['距離'] = df['距離'].str.extract(r'(\\d+)').astype(int)\n",
    "        \n",
    "        #インデックス名を与える\n",
    "        df.index.name = 'horse_id'\n",
    "    \n",
    "        self.horse_results = df\n",
    "        self.target_list = ['着順', '賞金', '着差', 'first_corner',\n",
    "                            'first_to_rank', 'first_to_final','final_to_rank']\n",
    "        \n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "            \n",
    "        average1 = filtered_df.groupby(level=0)[self.target_list].mean()\n",
    "        average2 = filtered_df.groupby(\n",
    "            ['horse_id', '開催', '距離', 'race_type']\n",
    "        )[self.target_list].mean().unstack(level=[1,2,3])\n",
    "        average2.columns = average2.columns.map(lambda x: '_'.join(x))\n",
    "        \n",
    "        average = pd.concat([average1, average2], axis=1).add_suffix(\n",
    "            '_{}R'.format(n_samples))\n",
    "        \n",
    "        return average\n",
    "    \n",
    "    # 省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d94f8-ea64-4752-abe4-efc241dd5a4c",
   "metadata": {},
   "source": [
    "# 概要 第26回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03ecd7-f5e9-4a5d-86e3-dcfebd813499",
   "metadata": {},
   "source": [
    "## 変数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703866be-52ec-4353-a5a4-4a95b9277eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_dict = {\n",
    "    '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "    '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "}\n",
    "\n",
    "race_type_dict = {\n",
    "    '芝': '芝', 'ダ': 'ダート', '障': '障害'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53dfba-4d3b-41fe-9419-c7c77712c8af",
   "metadata": {},
   "source": [
    "## HorseResultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2563c-7196-49c3-ad33-3c2b347a3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseResults:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付', '着順', '賞金', '着差', '通過',\n",
    "                                            '開催', '距離']]\n",
    "        self.preprocessing()\n",
    "    \n",
    "    #省略\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "        #race_type\n",
    "        df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "        #距離\n",
    "        df['course_len'] = df['距離'].str.extract(r'(\\d+)').astype(int) // 100\n",
    "        df.drop(['距離'], axis=1, inplace=True)\n",
    "        \n",
    "        #インデックス名を与える\n",
    "        df.index.name = 'horse_id'\n",
    "    \n",
    "        self.horse_results = df\n",
    "        self.target_list = ['着順', '賞金', '着差', 'first_corner',\n",
    "                            'first_to_rank', 'first_to_final','final_to_rank']\n",
    "        \n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "          \n",
    "        self.average_dict = {}\n",
    "        self.average_dict['non_category'] = filtered_df.groupby(level=0)[self.target_list]\\\n",
    "            .mean().add_suffix('_{}R'.format(n_samples))\n",
    "        for column in ['course_len', 'race_type', '開催']:\n",
    "            self.average_dict[column] = filtered_df.groupby(['horse_id', column])\\\n",
    "                [self.target_list].mean().add_suffix('_{}_{}R'.format(column, n_samples))\n",
    "\n",
    "    \n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        self.average(horse_id_list, date, n_samples)\n",
    "        merged_df = df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        for column in ['course_len','race_type', '開催']:\n",
    "            merged_df = merged_df.merge(self.average_dict[column], \n",
    "                                        left_on=['horse_id', column],\n",
    "                                        right_index=True, how='left')\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat(\n",
    "            [self.merge(results, date, n_samples) for date in tqdm(date_list)]\n",
    "        )\n",
    "        return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6196f5-e7c9-4537-aca5-c3dd81920499",
   "metadata": {},
   "source": [
    "## Resultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288a822-150f-43d9-9a8e-5dc2bc9fb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    #前処理    \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "        df['rank'] = df['着順'].map(lambda x:1 if x<4 else 0)\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "\n",
    "        # データをint, floatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名', '騎手', '単勝', '人気', '着順'],\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df.index.map(lambda x:str(x)[4:6])\n",
    "\n",
    "        self.data_p = df\n",
    "    \n",
    "    #カテゴリ変数の処理\n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "        super().process_categorical(self.le_horse, self.le_jockey, self.data_pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb06d3-5c2b-4c3e-a0c5-755823e8f8a0",
   "metadata": {},
   "source": [
    "## DataProcessorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a275c62-e266-4be6-a69b-740bb6258bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame() #raw data\n",
    "        self.data_p = pd.DataFrame() #after preprocessing\n",
    "        self.data_h = pd.DataFrame() #after merging horse_results\n",
    "        self.data_pe = pd.DataFrame() #after merging peds\n",
    "        self.data_c = pd.DataFrame() #after processing categorical features\n",
    "        \n",
    "    #馬の過去成績データの追加\n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        self.data_h = self.data_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.data_h = hr.merge_all(self.data_h, n_samples=n_samples)\n",
    "        self.data_h.drop(['開催'], axis=1, inplace=True)\n",
    "\t\n",
    "    #省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cdfda6-5cc6-41b9-a8f3-78a8934db132",
   "metadata": {},
   "source": [
    "## 注意点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3c84c-35cf-4054-a009-f507208929a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rate = len(df.query('win == 馬番')) / (100 / df['return']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e10ba4-3ac8-4966-96a5-527ac008b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rate = len(df.query('win == 馬番')) / (1 / df['単勝']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc8797-be2e-4896-a0a0-19751636d1de",
   "metadata": {},
   "source": [
    "# 概要 第27回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab80b4-85bf-4467-8ffb-6edff311768e",
   "metadata": {},
   "source": [
    "## Resultsクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39149328-7964-4879-b524-caad2b7ebdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    #省略\n",
    "    \n",
    "    #前処理    \n",
    "    def preprocessing(self):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "        df['rank'] = df['着順'].map(lambda x:1 if x<4 else 0)\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[1].str[:-1].astype(int)\n",
    "\n",
    "        # データをint, floatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        df[\"course_len\"] = df[\"course_len\"].astype(float) // 100\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\", '馬名', '騎手', '人気', '着順'],\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df.index.map(lambda x:str(x)[4:6])\n",
    "\n",
    "        self.data_p = df\n",
    "    \n",
    "    #カテゴリ変数の処理\n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "        super().process_categorical(self.le_horse, self.le_jockey, self.data_pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ced059-8434-4a0e-bf27-3d0b2a667ba6",
   "metadata": {},
   "source": [
    "## ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67544a4d-8cdb-45d8-807e-f2d4bfb7a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables_path, std=True):\n",
    "        self.model = model\n",
    "        self.rt = Return.read_pickle([return_tables_path])\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.std = std\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        proba = pd.Series(\n",
    "            self.model.predict_proba(X.drop(['単勝'], axis=1))[:, 1], index=X.index\n",
    "        )\n",
    "        if self.std:\n",
    "            #標準化： レース内で相対評価する\n",
    "            standard_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "            proba = proba.groupby(level=0).transform(standard_scaler)\n",
    "        proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "        return proba\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "    \n",
    "    def score(self, y_true, X):\n",
    "        return roc_auc_score(y_true, self.predict_proba(X))\n",
    "    \n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                    \"importance\": self.model.feature_importances_})\n",
    "        return importances.sort_values(\"importance\", ascending=False)[:n_display]\n",
    "    \n",
    "    def pred_table(self, X, threshold=0.5, bet_only=True):\n",
    "        pred_table = X.copy()[['馬番', '単勝']]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        if bet_only:\n",
    "            return pred_table[pred_table['pred']==1]['馬番', '単勝']\n",
    "        else:\n",
    "            return pred_table\n",
    "        \n",
    "    def fukusho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        money = -100 * n_bets\n",
    "        df = self.fukusho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        for i in range(3):\n",
    "            money += df[df['win_{}'.format(i)]==df['馬番']]['return_{}'.format(i)].sum()\n",
    "        return_rate = (n_bets*100 + money) / (n_bets*100)\n",
    "        return n_bets, return_rate\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        money = -100 * n_bets\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        n_hits = len(df[df['win']==df['馬番']])\n",
    "        money += df[df['win']==df['馬番']]['return'].sum()\n",
    "        return_rate = (n_bets*100 + money) / (n_bets*100)\n",
    "        return n_bets, return_rate, n_hits\n",
    "    \n",
    "    def tansho_return_proper(self, X, threshold=0.5):\n",
    "        #モデルによって「賭ける」と判断された馬たち\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        #払い戻し表にpred_tableをマージ\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        \n",
    "        #単勝適正回収値を計算\n",
    "        n_hits = len(df.query('win == 馬番'))\n",
    "        return_rate = n_hits / (1 / pred_table['単勝']).sum()\n",
    "        \n",
    "        return n_bets, return_rate, n_hits\n",
    "    \n",
    "    def umaren_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        hit = {}\n",
    "        n_bets = 0\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            n_bets += comb(len(preds, 2))\n",
    "            hit[race_id] = set(\n",
    "                self.umaren.loc[race_id][['win_0', 'win_1']]\n",
    "            ).issubset(set(preds))\n",
    "        return_rate = self.umaren.index.map(hit).values * self.umaren['return'].sum() / \\\n",
    "            (n_bets * 100)\n",
    "        return n_bets, return_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8ca5c-0620-4382-80b4-c46d411b0760",
   "metadata": {},
   "source": [
    "## gain関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412614bd-9ce6-49b9-a28d-c500a72f4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(return_func, X, n_samples=100, lower=50, min_threshold=0.5):\n",
    "    gain = {}\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        threshold = 1 * i / n_samples + min_threshold * (1-(i/n_samples))\n",
    "        n_bets, return_rate, n_hits = return_func(X, threshold)\n",
    "        if n_bets > lower:\n",
    "            gain[n_bets] = {'return_rate': return_rate, 'n_hits': n_hits}\n",
    "    return pd.DataFrame(gain).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de1bbc9-1121-40fb-88e6-5c90eb544bc7",
   "metadata": {},
   "source": [
    "## その他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c822c0-da83-4589-a09e-1f7cc59d0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(r.data_c)\n",
    "X_train = train.drop(['rank', 'date', '単勝'], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop(['rank', 'date'], axis=1)\n",
    "y_test = test['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc2e31-ed11-4ccb-8baf-d2798e0fbd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#回収率の比較\n",
    "g = gain(me.tansho_return_proper, X_test)\n",
    "g_tansho = gain(me.tansho_return, X_test)\n",
    "\n",
    "plt.plot(g.index, g['return_rate'])\n",
    "plt.plot(g_tansho.index, g_tansho['return_rate'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a29403-de51-4f0a-9bb8-16627e38b37c",
   "metadata": {},
   "source": [
    "# 概要 第28回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22652a2e-9168-4af5-b3cb-6c4f7e5525df",
   "metadata": {},
   "source": [
    "## ModelEvaluatorクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2323a7-242c-4b34-8359-233221a5b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, return_tables_path, std=True):\n",
    "        self.model = model\n",
    "        self.rt = Return.read_pickle([return_tables_path])\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.std = std\n",
    "    \n",
    "    #省略\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.5):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        n_races = pred_table.index.nunique()\n",
    "        \n",
    "        money = -100 * n_bets\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        \n",
    "        std = ((df['win'] == df['馬番']) * df['return']).groupby(level=0).sum().std() \\\n",
    "            np.sqrt(n_races) / (100 * n_bets)\n",
    "        \n",
    "        n_hits = len(df[df['win']==df['馬番']])\n",
    "        money += df[df['win']==df['馬番']]['return'].sum()\n",
    "        return_rate = (n_bets*100 + money) / (n_bets*100)\n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return_proper(self, X, threshold=0.5):\n",
    "        #モデルによって「賭ける」と判断された馬たち\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        n_races = pred_table.index.nunique()\n",
    "        \n",
    "        #払い戻し表にpred_tableをマージ\n",
    "        df = self.tansho.copy()\n",
    "        df = df.merge(pred_table, left_index=True, right_index=True, how='right')\n",
    "        \n",
    "        bet_money = (1 / pred_table['単勝']).sum()\n",
    "        \n",
    "        std = ((df['win'] == df['馬番']).astype(int)).groupby(level=0).sum().std() \\\n",
    "            * np.sqrt(n_races) / bet_money\n",
    "        \n",
    "        #単勝適正回収値を計算\n",
    "        n_hits = len(df.query('win == 馬番'))\n",
    "        return_rate = n_hits / bet_money\n",
    "        \n",
    "        return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    #省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da249e-39e8-445a-a609-0653f812b7ad",
   "metadata": {},
   "source": [
    "## gain関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f734a7dd-4f7f-4f3b-bbb2-4b6fe83c3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(return_func, X, n_samples=100, min_threshold=0.5):\n",
    "    gain = {}\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        threshold = 1 * i / n_samples + min_threshold * (1-(i/n_samples))\n",
    "        n_bets, return_rate, n_hits, std = return_func(X, threshold)\n",
    "        if n_bets > 2:\n",
    "            gain[n_bets] = {'return_rate': return_rate, 'n_hits': n_hits,\n",
    "                            'std': std}\n",
    "    return pd.DataFrame(gain).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d9727-491a-4b5e-8f12-50f5e61c6093",
   "metadata": {},
   "source": [
    "## プロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ccc0c-2a83-46cf-9995-f85e4384e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tansho = gain(me.tansho_return, X_test)\n",
    "g_proper = gain(me.tansho_return_proper, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9eaa6e-23b1-440a-87cf-1549b481e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(g_tansho.index, y1=g_tansho['return_rate']-g_tansho['std'],\n",
    "                 y2=g_tansho['return_rate']+g_tansho['std'],\n",
    "                 alpha=0.3)\n",
    "plt.plot(g_tansho.index, g_tansho['return_rate'], label='tansho')\n",
    "plt.fill_between(g_proper.index, y1=g_proper['return_rate']-g_proper['std'],\n",
    "                 y2=g_proper['return_rate']+g_proper['std'],\n",
    "                 alpha=0.3)\n",
    "plt.plot(g_proper.index, g_proper['return_rate'], label='proper')\n",
    "\n",
    "plt.xlim(-10, 1000)\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ee39d-91c4-4c0d-bf36-9621e5ff3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_tansho.index, (g_tansho['return_rate'] - 1) / g_tansho['std'], label='tansho')\n",
    "plt.plot(g_proper.index, (g_proper['return_rate'] - 1) / g_proper['std'], label='proper')\n",
    "\n",
    "plt.xlim(-10, 1000)\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
